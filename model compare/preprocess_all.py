import os
import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler

# è¨­å®šä½ çš„è³‡æ–™å¤¾è·¯å¾‘ï¼ˆè«‹ä¾å¯¦éš›ä¿®æ”¹ï¼‰
BASE_PATH = r"C:\Users\boss9\OneDrive\æ¡Œé¢\å°ˆé¡Œ\æ©Ÿå™¨å­¸ç¿’\dataset\feature dim_4\hardware"

# ğŸ”§ ä½¿ç”¨çš„æ¬„ä½ï¼ˆå¯ä»¥åˆªæ‰å…¶ä¸­ä¸€å€‹ï¼‰
SELECTED_FEATURES = ["current", "voltage",  "power", "temp_C"]

# å„åˆ†é¡è³‡æ–™å¤¾å°æ‡‰æ¨™ç±¤
LABEL_DIRS = {
    0: os.path.join(BASE_PATH, "normal"),
    1: os.path.join(BASE_PATH, "abnormal", "wire_rust"),
    2: os.path.join(BASE_PATH, "abnormal", "transformer_rust"),
    3: os.path.join(BASE_PATH, "abnormal", "transformer_overheating"),
}

# âœ… å¿«å–æ ¹ç›®éŒ„ï¼ˆä½ æƒ³è¦çš„è¼¸å‡ºä½ç½®ï¼‰
CACHE_ROOT = os.path.join(BASE_PATH, "preprocessed")

# å»ºç«‹ 3D å¿«å–è³‡æ–™
def generate_preprocessed_cache_3d(seq_lens, label_dirs,  cache_dir = CACHE_ROOT):
    os.makedirs(cache_dir, exist_ok=True)
    for seq_len in seq_lens:
        cache_X = os.path.join(cache_dir, f"X_seq{seq_len}_3d.npy")
        cache_y = os.path.join(cache_dir, f"y_seq{seq_len}_3d.npy")

        if os.path.exists(cache_X) and os.path.exists(cache_y):
            print(f"ğŸ“¥ å·²å­˜åœ¨ 3D å¿«å–ï¼šseq_len={seq_len}ï¼Œç•¥é")
            continue

        all_seq, all_labels = [], []
        for label, folder in label_dirs.items():
            for fname in os.listdir(folder):
                if fname.endswith(".csv"):
                    path = os.path.join(folder, fname)
                    df = pd.read_csv(path)
                    try:
                        data = df[SELECTED_FEATURES].values.astype(np.float32)
                    except KeyError as e:
                        print(f"âŒ ç¼ºå°‘æ¬„ä½ {e}ï¼š{path}")
                        continue

                    num_chunks = len(data) // seq_len
                    chunks = [data[i * seq_len : (i + 1) * seq_len] for i in range(num_chunks)]
                    all_seq.extend(chunks)
                    all_labels.extend([label] * len(chunks))

        if not all_seq:
            print(f"âš ï¸ ç„¡å¯ç”¨è³‡æ–™ï¼Œè·³é seq_len={seq_len}")
            continue

        seq_arr = np.array(all_seq, dtype=np.float32)
        labels_arr = np.array(all_labels, dtype=np.int64)
        B, T, F = seq_arr.shape

        reshaped = seq_arr.reshape(-1, F)
        scaled = StandardScaler().fit_transform(reshaped).reshape(B, T, F)

        np.save(cache_X, scaled)
        np.save(cache_y, labels_arr)
        print(f"âœ… å®Œæˆ 3D å¿«å–ï¼šseq_len={seq_len}ï¼ˆå…± {B} ç­†åºåˆ—ï¼‰")

# å»ºç«‹ 2D å¿«å–è³‡æ–™
def generate_preprocessed_cache_2d(seq_lens, label_dirs,  cache_dir = CACHE_ROOT):
    os.makedirs(cache_dir, exist_ok=True)
    for seq_len in seq_lens:
        cache_X = os.path.join(cache_dir, f"X_seq{seq_len}_2d.npy")
        cache_y = os.path.join(cache_dir, f"y_seq{seq_len}_2d.npy")

        if os.path.exists(cache_X) and os.path.exists(cache_y):
            print(f"ğŸ“¥ å·²å­˜åœ¨ 2D å¿«å–ï¼šseq_len={seq_len}ï¼Œç•¥é")
            continue

        all_features, all_labels = [], []
        for label, folder in label_dirs.items():
            for fname in os.listdir(folder):
                if fname.endswith(".csv"):
                    path = os.path.join(folder, fname)
                    df = pd.read_csv(path)
                    try:
                        data = df[SELECTED_FEATURES].values.astype(np.float32)
                    except KeyError as e:
                        print(f"âŒ ç¼ºå°‘æ¬„ä½ {e}ï¼š{path}")
                        continue

                    num_chunks = len(data) // seq_len
                    chunks = [data[i * seq_len : (i + 1) * seq_len] for i in range(num_chunks)]
                    for chunk in chunks:
                        flattened = chunk.flatten()  # ğŸŒŸ é‡é»ï¼šç›´æ¥æ”¤å¹³
                        all_features.append(flattened)
                        all_labels.append(label)

        if not all_features:
            print(f"âš ï¸ ç„¡å¯ç”¨è³‡æ–™ï¼Œè·³é seq_len={seq_len}")
            continue

        X = np.array(all_features, dtype=np.float32)
        y = np.array(all_labels, dtype=np.int64)

        X_scaled = StandardScaler().fit_transform(X)

        np.save(cache_X, X_scaled)
        np.save(cache_y, y)
        print(f"âœ… å®Œæˆ 2D å¿«å–ï¼šseq_len={seq_len}ï¼ˆå…± {len(X_scaled)} ç­†ï¼Œshape: {X_scaled.shape}ï¼‰")

# ä¸»åŸ·è¡Œé‚è¼¯
if __name__ == "__main__":
    seq_lens = [10, 20, 30, 40]

    print("ğŸ” é–‹å§‹å»ºç«‹ 3D å¿«å–")
    generate_preprocessed_cache_3d(seq_lens, LABEL_DIRS)

    print("\nğŸ” é–‹å§‹å»ºç«‹ 2D å¿«å–")
    generate_preprocessed_cache_2d(seq_lens, LABEL_DIRS)

    print("\nğŸ‰ æ‰€æœ‰å¿«å–å»ºç«‹å®Œæˆï¼")
