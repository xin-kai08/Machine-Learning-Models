import time
from threading import Lock, Thread

import joblib
import numpy as np
import pandas as pd
import serial
import torch
from flask import Flask, jsonify
from flask_cors import CORS
import ctypes
import winsound
from model import LSTMClassifier

# === åƒæ•¸è¨­å®š ===
COM_PORT = "COM14"
BAUD_RATE = 9600
MAX_SEQ_LEN = 10
INPUT_DIM = 4
HIDDEN_DIM = 16
NUM_LAYERS = 4
NUM_CLASSES = 4
TEMP_THRESHOLD = 40

# === è¼‰å…¥æ¨¡å‹èˆ‡ scaler ===
model = LSTMClassifier(INPUT_DIM, HIDDEN_DIM, NUM_LAYERS, NUM_CLASSES)
model.load_state_dict(
    torch.load(
        r"C:\Users\boss9\OneDrive\æ¡Œé¢\å°ˆé¡Œ\æ©Ÿå™¨å­¸ç¿’\esp to python\0626_fold_5_model.pth",
        map_location=torch.device("cpu"),
    )
)
model.eval()
scaler = joblib.load("0626_scaler_fold5.pkl")

LABEL_NAMES = {
    0: "æ­£å¸¸",
    1: "å……é›»ç·šç”Ÿé½",
    2: "è®Šå£“å™¨ç”Ÿé½",
    3: "è®Šå£“å™¨éç†±",
}
feature_names = ["current", "voltage", "power", "temp_C"]

# === ç·©è¡å€èˆ‡ç‹€æ…‹ ===
sequence_buffer = []
raw_sequence_buffer = []
prev_predicted = 0
pause_reading = False

# === Flask ä¼ºæœå™¨ ===
app = Flask(__name__)
CORS(app)  # âœ… ä¿è­‰è·¨åŸŸï¼Œçµ¦ APP ç”¨
result_lock = Lock()
latest_result = {}

@app.route("/get_result")
def get_result():
    with result_lock:
        return jsonify(latest_result if latest_result else {})

def update_result(predicted, label, input_sequence, feature_names):
    with result_lock:
        latest_result["predicted"] = int(predicted)
        latest_result["label"] = label
        latest_result["sequence"] = [
            {name: float(val) for name, val in zip(feature_names, row)}
            for row in input_sequence
        ]
        latest_result["timestamp"] = time.time()

def serial_inference_loop():
    ser = serial.Serial(COM_PORT, BAUD_RATE)
    print(f"âœ… Serial å·²é€£æ¥ï¼š{COM_PORT} @ {BAUD_RATE} baud")

    global sequence_buffer, raw_sequence_buffer, prev_predicted, pause_reading

    while True:
        try:
            if pause_reading:
                time.sleep(0.1)
                continue

            line = ser.readline().decode("utf-8").strip()
            if not line:
                continue

            try:
                input_data = list(map(float, line.split(",")))
            except Exception as e:
                print(f"âŒ æ•¸æ“šè§£æéŒ¯èª¤: {line} â†’ {e}")
                continue

            if len(input_data) != len(feature_names):
                print(f"âŒ æ•¸æ“šé•·åº¦éŒ¯èª¤: {input_data}")
                continue

            input_df = pd.DataFrame([input_data], columns=feature_names)
            scaler_cols = getattr(scaler, "feature_names_in_", feature_names)
            input_df = input_df[scaler_cols]
            input_scaled = scaler.transform(input_df.values)[0]
            sequence_buffer.append(input_scaled)
            raw_sequence_buffer.append(input_data)

            print(f"ğŸ“¥ æ”¶åˆ°ç¬¬ {len(sequence_buffer)} ç­†: {input_data}")

            if len(sequence_buffer) == MAX_SEQ_LEN:
                input_tensor = torch.tensor([sequence_buffer], dtype=torch.float32)
                with torch.no_grad():
                    output = model(input_tensor)
                    predicted = torch.argmax(output, dim=1).item()
                    label = LABEL_NAMES.get(predicted, f"æœªçŸ¥é¡åˆ¥ {predicted}")

                    # === é›™å‘æº«åº¦å¾Œè™•ç† ===
                    try:
                        temp_idx = feature_names.index("temp_C")
                        last_temp = raw_sequence_buffer[-1][temp_idx]
                        if label == "è®Šå£“å™¨éç†±" and last_temp < TEMP_THRESHOLD:
                            print(f"âš ï¸ éç†±æ ¡æ­£ â†’ æº«åº¦ {last_temp:.1f}Â°C æœªé”é–€æª»ï¼Œæ”¹åˆ¤æ­£å¸¸")
                            predicted = 0
                            label = "éç†±ä¿®æ­£"
                        elif label == "æ­£å¸¸" and last_temp >= TEMP_THRESHOLD:
                            print(f"âš ï¸ æ­£å¸¸æ ¡æ­£ â†’ æº«åº¦ {last_temp:.1f}Â°C è¶…é–€æª»ï¼Œå¼·åˆ¶éç†±")
                            predicted = 3
                            label = "éç†±ï¼ˆæº«åº¦æ ¡æ­£ï¼‰"
                    except Exception as e:
                        print(f"âš ï¸ å¾Œè™•ç†å¤±æ•—ï¼š{e}")

                    result_sequence = raw_sequence_buffer.copy()

                    # === çµ‚ç«¯è¼¸å‡º ===
                    if predicted != 0 and predicted != prev_predicted:
                        print(f"âš ï¸âš ï¸âš ï¸ æ–°ç•°å¸¸ï¼š{predicted} â†’ {label}")
                    elif predicted != 0:
                        print(f"ğŸ”„ ç•°å¸¸æŒçºŒä¸­ï¼š{predicted} â†’ {label}")
                    else:
                        print("âœ… æ­£å¸¸ç‹€æ…‹")

                    # === è·³çª—é‚è¼¯ï¼ˆåƒ…æ–°ç•°å¸¸ï¼‰
                    if predicted != 0 and predicted != prev_predicted:
                        pause_reading = True
                        ser.close()
                        print("ğŸ›‘ Serial å·²é—œé–‰ï¼Œæš«åœæ¥æ”¶")

                        sequence_buffer.clear()
                        raw_sequence_buffer.clear()
                        with result_lock:
                            latest_result.clear()

                        winsound.Beep(1000, 500)
                        ctypes.windll.user32.MessageBoxW(
                            0, f"åµæ¸¬åˆ°ç•°å¸¸ï¼š{label}", "âš ï¸ ç³»çµ±è­¦å‘Š", 0x30
                        )

                        ser.open()
                        ser.reset_input_buffer()
                        print("âœ… Serial å·²é‡æ–°é–‹å•Ÿ")
                        pause_reading = False

                    prev_predicted = 0 if predicted == 0 else predicted

                    update_result(predicted, label, result_sequence, scaler_cols)

                sequence_buffer.clear()
                raw_sequence_buffer.clear()

            time.sleep(0.1)

        except KeyboardInterrupt:
            print("\nğŸ›‘ ä½¿ç”¨è€…ä¸­æ–·")
            break
        except Exception as e:
            print(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

if __name__ == "__main__":
    t = Thread(target=serial_inference_loop)
    t.daemon = True
    t.start()
    app.run(host="0.0.0.0", port=8080)